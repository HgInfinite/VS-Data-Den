{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize = 10 ** 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = '/Users/harshitgupta/Downloads/idsa_data 2/_SELECT_hs_STOREID_hs_SALES_hs_SALESLOCALCURRENCY_hs_UNITS_hs_YE_202404161522.csv'\n",
    "\n",
    "# Parquet file path\n",
    "parquet_file = '/Users/harshitgupta/Downloads/idsa_data 2/grouped_sales.parquet'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(parquet_file):\n",
    "    # Read existing Parquet file\n",
    "    existing_data = pd.read_parquet(parquet_file)\n",
    "else:\n",
    "    existing_data = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk 1\n",
      "Processed chunk 2\n",
      "Processed chunk 3\n",
      "Processed chunk 4\n",
      "Processed chunk 5\n",
      "Processed chunk 6\n",
      "Processed chunk 7\n",
      "Processed chunk 8\n",
      "Processed chunk 9\n",
      "Processed chunk 10\n",
      "Processed chunk 11\n",
      "Processed chunk 12\n",
      "Processed chunk 13\n",
      "Processed chunk 14\n",
      "Processed chunk 15\n",
      "Processed chunk 16\n",
      "Processed chunk 17\n",
      "Processed chunk 18\n",
      "Processed chunk 19\n",
      "Processed chunk 20\n",
      "Processed chunk 21\n",
      "Processed chunk 22\n",
      "Processed chunk 23\n",
      "Processed chunk 24\n",
      "Processed chunk 25\n",
      "Processed chunk 26\n",
      "Processed chunk 27\n",
      "Processed chunk 28\n",
      "Processed chunk 29\n",
      "Processed chunk 30\n",
      "Processed chunk 31\n",
      "Processed chunk 32\n",
      "Processed chunk 33\n",
      "Processed chunk 34\n",
      "Processed chunk 35\n",
      "Processed chunk 36\n",
      "Processed chunk 37\n",
      "Processed chunk 38\n",
      "Processed chunk 39\n",
      "Processed chunk 40\n",
      "Processed chunk 41\n",
      "Processed chunk 42\n",
      "Processed chunk 43\n",
      "Processed chunk 44\n",
      "Processed chunk 45\n",
      "Processed chunk 46\n",
      "Processed chunk 47\n",
      "Processed chunk 48\n",
      "Processed chunk 49\n",
      "Processed chunk 50\n",
      "Processed chunk 51\n",
      "Processed chunk 52\n",
      "Processed chunk 53\n",
      "Processed chunk 54\n",
      "Processed chunk 55\n",
      "Processed chunk 56\n",
      "Processed chunk 57\n",
      "Processed chunk 58\n",
      "Processed chunk 59\n",
      "Processed chunk 60\n",
      "Processed chunk 61\n",
      "Processed chunk 62\n",
      "Processed chunk 63\n",
      "Processed chunk 64\n",
      "Processed chunk 65\n",
      "Processed chunk 66\n",
      "Processed chunk 67\n",
      "Processed chunk 68\n",
      "Processed chunk 69\n",
      "Processed chunk 70\n",
      "Processed chunk 71\n",
      "Processed chunk 72\n",
      "Processed chunk 73\n",
      "Processed chunk 74\n",
      "Processed chunk 75\n",
      "Processed chunk 76\n",
      "Processed chunk 77\n",
      "Processed chunk 78\n",
      "Processed chunk 79\n",
      "Processed chunk 80\n",
      "Processed chunk 81\n",
      "Processed chunk 82\n",
      "Processed chunk 83\n",
      "Processed chunk 84\n",
      "Processed chunk 85\n",
      "Processed chunk 86\n",
      "Processed chunk 87\n",
      "Processed chunk 88\n",
      "Processed chunk 89\n",
      "Processed chunk 90\n",
      "Processed chunk 91\n",
      "Processed chunk 92\n",
      "Processed chunk 93\n",
      "Processed chunk 94\n",
      "Processed chunk 95\n",
      "Processed chunk 96\n",
      "Processed chunk 97\n",
      "Processed chunk 98\n",
      "Processed chunk 99\n",
      "Processed chunk 100\n",
      "Processed chunk 101\n",
      "Processed chunk 102\n",
      "Processed chunk 103\n",
      "Processed chunk 104\n",
      "Processed chunk 105\n",
      "Processed chunk 106\n",
      "Processed chunk 107\n",
      "Processed chunk 108\n",
      "Processed chunk 109\n",
      "Processed chunk 110\n",
      "Processed chunk 111\n",
      "Processed chunk 112\n",
      "Processed chunk 113\n",
      "Processed chunk 114\n",
      "Processed chunk 115\n",
      "Processed chunk 116\n",
      "Processed chunk 117\n",
      "Processed chunk 118\n",
      "Processed chunk 119\n",
      "Processed chunk 120\n",
      "Processed chunk 121\n",
      "Processed chunk 122\n",
      "Processed chunk 123\n",
      "Processed chunk 124\n",
      "Processed chunk 125\n",
      "Processed chunk 126\n",
      "Processed chunk 127\n",
      "Processed chunk 128\n",
      "Processed chunk 129\n",
      "Processed chunk 130\n",
      "Processed chunk 131\n",
      "Processed chunk 132\n",
      "Processed chunk 133\n",
      "Processed chunk 134\n",
      "Processed chunk 135\n",
      "Processed chunk 136\n",
      "Processed chunk 137\n",
      "Processed chunk 138\n",
      "Processed chunk 139\n",
      "Processed chunk 140\n",
      "Conversion to Parquet completed successfully.\n"
     ]
    }
   ],
   "source": [
    "chunks = pd.read_csv(csv_file, chunksize=chunksize)\n",
    "for i, chunk in enumerate(chunks):\n",
    "    if existing_data is not None:\n",
    "        # Concatenate existing data with current chunk\n",
    "        combined_data = pd.concat([existing_data, chunk], ignore_index=True)\n",
    "    else:\n",
    "        combined_data = chunk\n",
    "\n",
    "    # Save combined data to Parquet\n",
    "    combined_data.to_parquet(parquet_file, index=False)\n",
    "    print(f\"Processed chunk {i+1}\")\n",
    "\n",
    "print(\"Conversion to Parquet completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
